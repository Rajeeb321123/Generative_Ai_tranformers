{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13f2e232-de32-4e31-b684-08d7f2cedef2",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13d20e6e-629d-476c-a0d2-2db9b6ef7a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f4a5fcf-0c89-4228-a332-7c48bb0db3e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is outdoors, on a horse.</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>There are children present</td>\n",
       "      <td>The kids are frowning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
       "      <td>The boy does a skateboarding trick.</td>\n",
       "      <td>The boy skates down the sidewalk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two blond women are hugging one another.</td>\n",
       "      <td>There are women showing affection.</td>\n",
       "      <td>The women are sleeping.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A few people in a restaurant setting, one of t...</td>\n",
       "      <td>The diners are at a restaurant.</td>\n",
       "      <td>The people are sitting at desks in school.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              anchor  \\\n",
       "0  A person on a horse jumps over a broken down a...   \n",
       "1              Children smiling and waving at camera   \n",
       "2  A boy is jumping on skateboard in the middle o...   \n",
       "3           Two blond women are hugging one another.   \n",
       "4  A few people in a restaurant setting, one of t...   \n",
       "\n",
       "                              positive  \\\n",
       "0    A person is outdoors, on a horse.   \n",
       "1           There are children present   \n",
       "2  The boy does a skateboarding trick.   \n",
       "3   There are women showing affection.   \n",
       "4      The diners are at a restaurant.   \n",
       "\n",
       "                                        negative  \n",
       "0  A person is at a diner, ordering an omelette.  \n",
       "1                          The kids are frowning  \n",
       "2              The boy skates down the sidewalk.  \n",
       "3                        The women are sleeping.  \n",
       "4     The people are sitting at desks in school.  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset_1 = load_dataset(\"sentence-transformers/all-nli\",\"triplet\", split = \"train\", cache_dir='cache_dir_dataset').to_pandas()\n",
    "dataset_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b653026-14d6-4ed2-b9d6-838ecb0df1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Dropped rows: 0\n",
      "total number of null values in dataset_1 and df: 0 and 0\n"
     ]
    }
   ],
   "source": [
    "# droping any row with null value\n",
    "df = dataset_1.dropna(axis=0)\n",
    "df = a = df.reset_index(drop =True) # index is all messed up after drop so we resetindex.\n",
    "print(\"The number of Dropped rows:\",dataset_1.shape[0]-df.shape[0])\n",
    "null_count_dataset_1 = dataset_1.isnull().sum().sum()\n",
    "null_count_df = df.isnull().sum().sum()\n",
    "print(\"total number of null values in dataset_1 and df:\",null_count_dataset_1, \"and\", null_count_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7e45574-6845-405e-a55d-da85125ac342",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92119414\n"
     ]
    }
   ],
   "source": [
    "# counting total character in dataset\n",
    "total_character = 0\n",
    "for index_1, row in df.iterrows():\n",
    "    total_character = len(row[\"anchor\"]) + len(row[\"positive\"]) + len(row[\"negative\"]) + total_character\n",
    "print(total_character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e664ca3b-1350-4ce9-943d-27ee634b6234",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# counting the number of value we won't going to translate\n",
    "no_translate = 0\n",
    "for index_1, row in df.iterrows():\n",
    "    if (len(row[\"anchor\"]) == 0):\n",
    "        no_translate += 1\n",
    "    if (len(row[\"positive\"]) == 0):\n",
    "        no_translate += 1\n",
    "    if (len(row[\"negative\"]) == 0):\n",
    "        no_translate += 1\n",
    "print(no_translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "554ca0c2-650d-4c6f-a86c-445bd90dfc17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557850, 557850)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len of dataset\n",
    "len(df), len(dataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c3ee5f3-35fb-49cf-8f80-e06b02d1c435",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rechecking the null value\n",
    "null_count_df = df.isnull().sum().sum()\n",
    "null_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2df9a44-4728-4274-9726-6e035a28c176",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rechecking the null value\n",
    "null_count_df = df.isnull().sum().sum()\n",
    "null_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48ae3e89-84e9-4769-9c23-d563239dbe0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1815\n"
     ]
    }
   ],
   "source": [
    "# Checking the max_length in whole dataset\n",
    "max_length = 0\n",
    "max_index = 0\n",
    "for index, row in df.iterrows():\n",
    "    if (len(row[\"anchor\"])> max_length):\n",
    "        max_length = len(row[\"anchor\"])\n",
    "        max_index = index\n",
    "    if (len(row[\"positive\"])> max_length):\n",
    "        max_length = len(row[\"positive\"])\n",
    "        max_index = index\n",
    "    if (len(row[\"negative\"])> max_length):\n",
    "        max_length = len(row[\"negative\"])\n",
    "        max_index = index\n",
    "    \n",
    "    \n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "605023a6-1ee5-4926-b679-f52ad47dacef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['anchor', 'positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b7a8601-dd1c-443f-b584-d0dde2a59870",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m temp_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(new_dic)\n\u001b[0;32m     12\u001b[0m df_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_1, temp_df], ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mdf_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(index\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10000\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(index)\n",
      "File \u001b[1;32md:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:6210\u001b[0m, in \u001b[0;36mDataFrame.reset_index\u001b[1;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[0;32m   6207\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(name_lst)\n\u001b[0;32m   6209\u001b[0m \u001b[38;5;66;03m# to ndarray and maybe infer different dtype\u001b[39;00m\n\u001b[1;32m-> 6210\u001b[0m level_values \u001b[38;5;241m=\u001b[39m \u001b[43mlev\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\n\u001b[0;32m   6211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level_values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m   6212\u001b[0m     level_values \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(level_values)\n",
      "File \u001b[1;32md:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5151\u001b[0m, in \u001b[0;36mIndex._values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5127\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m   5128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_values\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ExtensionArray \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   5129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5130\u001b[0m \u001b[38;5;124;03m    The best array representation.\u001b[39;00m\n\u001b[0;32m   5131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5149\u001b[0m \u001b[38;5;124;03m    values : Values\u001b[39;00m\n\u001b[0;32m   5150\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\n",
      "File \u001b[1;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:241\u001b[0m, in \u001b[0;36mRangeIndex._data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_data\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m    An int array that for performance reasons is created only when needed.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    The constructed array is saved in ``_cache``.\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#filter for small length\n",
    "limit_length = 500\n",
    "for index, row in df.iterrows():\n",
    "    if (len(row[\"anchor\"])> limit_length):\n",
    "        continue\n",
    "    if (len(row[\"positive\"])> max_length):\n",
    "        continue\n",
    "    if (len(row[\"negative\"])> max_length):\n",
    "        continue\n",
    "    new_dic = {\"anchor\": [row[\"anchor\"]], \"positive\": [row[\"positive\"]], \"negative\": [row[\"negative\"]] }\n",
    "    temp_df = pd.DataFrame(new_dic)\n",
    "    df_1 = pd.concat([df_1, temp_df], ignore_index = True)\n",
    "    df_1.reset_index()\n",
    "    if(index%10000==0):\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d495506-69c4-44ba-ac38-b823c4d39866",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123342"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298397f6-d120-47b4-b2b5-f80027ef2cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.iloc[534860][\"anchor\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b7a62f-16b2-474a-a7a0-2bea0b306d25",
   "metadata": {},
   "source": [
    "# for Initial (save the out.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3d76c-5f09-4ade-b77e-ef7eae2f4366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(columns=['anchor', 'positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00613b1f-cf83-4b0d-ba05-8ed8e38d52f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7ed64-15f5-446d-8b5d-80d64b82349e",
   "metadata": {},
   "source": [
    "### api call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aee64b-7024-4a01-b5fc-0500be9f460b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "template=\"\"\"Below is instruction that describes a task, paired with input which provide further context. Write a response  that appropriately complete the request.\n",
    "\n",
    "### Instruction:\n",
    "Translate this sentences or paragraphs to Nepali: {}\n",
    "\n",
    "### Input:\n",
    "\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "API_URL = \"https://v4uczsyh1spjupue.us-east-1.aws.endpoints.huggingface.cloud\"\n",
    "headers = {\n",
    " \"Accept\" : \"application/json\",\n",
    " \"Authorization\": \"Bearer hf_xxxxxxxxxx\",\n",
    " \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "def api_huggingface_llm(question):\n",
    "    if (len(question) > 0):\n",
    "        payload = {\n",
    "                \"inputs\": template.format(question),\n",
    "                \"parameters\": {\n",
    "                'max_new_tokens':2048,\n",
    "                'temperature': 0.1,\n",
    "                # 'repetition_penalty': 1,\n",
    "                \"return_full_text\": False\n",
    "            }}\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "        generated_answer = response.json()\n",
    "        return generated_answer[0][\"generated_text\"]\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a5b65-35b1-4245-b872-f4f4242f7197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_huggingface_llm(\"\"\"\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef801d0-2a73-495a-9e07-48e42a249962",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for index, row in df[0:10].iterrows():\n",
    "    \n",
    "    nepali_anchor = api_huggingface_llm(row[\"anchor\"])\n",
    "    nepali_positive = api_huggingface_llm(row[\"positive\"])\n",
    "    nepali_negative = api_huggingface_llm(row[\"negative\"])\n",
    "    \n",
    "    new_dic = {\"anchor\": [nepali_anchor], \"positive\": [nepali_positive], \"negative\": [nepali_negative] }\n",
    "    temp_df = pd.DataFrame(new_dic)\n",
    "    # display(temp_df)\n",
    "\n",
    "    df_2 = pd.concat([df_2, temp_df], ignore_index = True)\n",
    "    df_2.reset_index()\n",
    "    df_2.to_csv('out.csv')\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f79aa6-82d2-49df-af91-70e963fc0e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2.iloc[1][\"negative\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

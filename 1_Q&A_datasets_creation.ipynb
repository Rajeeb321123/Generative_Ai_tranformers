{"cells":[{"cell_type":"markdown","source":["# Turn any pdf to Q&A dataset for finetunning llm\n","\n","- I used locally runned llama3-instruct-8b with the help of lmstudio instead of openai api"],"metadata":{"id":"k5lUSdTUsytC"},"id":"k5lUSdTUsytC"},{"cell_type":"markdown","id":"507403a5-c348-4ae7-9c5d-3eef39658854","metadata":{"tags":[],"id":"507403a5-c348-4ae7-9c5d-3eef39658854"},"source":["## Installing the libraries\n"]},{"cell_type":"code","source":["%%capture\n","!pip install PyMuPDF\n","!pip install pytesseract\n","!pip install PIL\n","!pip install openai"],"metadata":{"id":"OkVKF5_ctFk7"},"id":"OkVKF5_ctFk7","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"90880447-85fd-4488-9a9b-9249b1637ea3","metadata":{"id":"90880447-85fd-4488-9a9b-9249b1637ea3"},"source":["## PDF to text"]},{"cell_type":"code","execution_count":null,"id":"c5cc342a-918d-4b26-beca-09aeebf8629f","metadata":{"id":"c5cc342a-918d-4b26-beca-09aeebf8629f"},"outputs":[],"source":["import fitz  # PyMuPDF\n","import pytesseract\n","from PIL import Image\n","import io\n","\n","\n","def convert_pdf_to_text(pdf_path ):\n","    # Open the PDF file\n","    document = fitz.open(pdf_path)\n","\n","    text = \"\"  # Initialize a text string to hold all text from the PDF\n","\n","    for page_num in range(len(document)):\n","        # Get the page\n","        page = document.load_page(page_num)\n","\n","        # First, try to extract text using PyMuPDF\n","        text_content = page.get_text()\n","\n","        if text_content.strip():  # If text is found, append it.\n","            text += text_content\n","        else:\n","            # If no text is found, it might be an image-based PDF\n","            # Extract the image from the page\n","            for img_index, img in enumerate(page.get_images(full=True)):\n","                xref = img[0]\n","                base_image = document.extract_image(xref)\n","                image_bytes = base_image[\"image\"]\n","\n","                # Load it to PIL\n","                image = Image.open(io.BytesIO(image_bytes))\n","\n","                # Use pytesseract to do OCR on the image\n","                text += pytesseract.image_to_string(image)\n","\n","    # Close the document\n","    document.close()\n","\n","    text = text.strip()\n","    text = \" \".join(text.split())\n","\n","\n","    return text"]},{"cell_type":"code","execution_count":null,"id":"6a8baebc-6317-45f7-9fd3-06d2e3b244bd","metadata":{"id":"6a8baebc-6317-45f7-9fd3-06d2e3b244bd"},"outputs":[],"source":["# Usage\n","pdf_path = \"/content/Constitution-of-Nepal.pdf\""]},{"cell_type":"code","execution_count":null,"id":"6f5b3916-9b53-4ee8-b61c-5c03868696a6","metadata":{"tags":[],"id":"6f5b3916-9b53-4ee8-b61c-5c03868696a6"},"outputs":[],"source":["text = convert_pdf_to_text(pdf_path )"]},{"cell_type":"code","execution_count":null,"id":"52905ca0-c905-488b-931d-efff42e2e4e4","metadata":{"tags":[],"id":"52905ca0-c905-488b-931d-efff42e2e4e4"},"outputs":[],"source":["print(text[:100])"]},{"cell_type":"markdown","id":"23ab293c-53be-4a73-801c-02cbc2bf8db6","metadata":{"id":"23ab293c-53be-4a73-801c-02cbc2bf8db6"},"source":["# Main body: text to Q&A response.json"]},{"cell_type":"code","execution_count":null,"id":"ee42ff44-76ba-4b77-9a0e-049f7b1d67dc","metadata":{"tags":[],"id":"ee42ff44-76ba-4b77-9a0e-049f7b1d67dc"},"outputs":[],"source":["# Chat with an intelligent assistant in your terminal\n","from openai import OpenAI\n","\n","# Point to the local server\n","client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n","\n","history = [\n","    {\"role\": \"system\", \"content\": \"You are an API that converts bodies of text into a single question and answer into a JSON format from the text provided by user. Each JSON contains a single question with a single answer. Only respond with the JSON and no additional text.\"},\n","]\n","\n","def run(user_input):\n","    history.append({\"role\": \"user\", \"content\": user_input})\n","    if (len(history)>4):\n","        query = history[:2] + history[-2:]\n","    else:\n","        query = history\n","\n","    completion = client.chat.completions.create(\n","        model=\"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\",\n","        messages=query,\n","        temperature=0.7,\n","        stream=True,\n","    )\n","\n","    print(completion)\n","    new_message = {\"role\": \"assistant\", \"content\": \"\"}\n","\n","    for chunk in completion:\n","        if chunk.choices[0].delta.content:\n","            print(chunk.choices[0].delta.content, end=\"\", flush=True)\n","            new_message[\"content\"] += chunk.choices[0].delta.content\n","\n","    history.append(new_message)\n","\n","    return new_message[\"content\"]\n"]},{"cell_type":"code","execution_count":null,"id":"1fae4161-203f-40a0-a9fd-2e2108f2bac2","metadata":{"tags":[],"id":"1fae4161-203f-40a0-a9fd-2e2108f2bac2"},"outputs":[],"source":["def chunks(lst, n):\n","    for i in range(0, len(lst), n):\n","        yield lst[i:i + n]\n","\n","def is_json(data):\n","    try:\n","        json.loads(data)\n","        return True\n","    except ValueError:\n","        return False\n","\n","def submit_to_api(chunk, retries=3):\n","    for i in range(retries):\n","        try:\n","            response = run(chunk)\n","            # Extract JSON string from between back-ticks\n","            if is_json(response):\n","                print(response)\n","                return json.loads(response)\n","            else:\n","                match = re.search(r'`(.*?)`', response, re.S)\n","                if match and is_json(match.group(1)):\n","                    print(f\"Attempt {i + 1} failed. Retrying...\")\n","                    return json.loads(match.group(1))  # assuming you want to return the JSON data\n","                else:\n","                    print(f\"Request failed: {e}\")\n","        except requests.exceptions.RequestException as e:\n","            continue\n","    print(\"Max retries exceeded. Skipping this chunk.\")\n","    return None\n","\n","\n","all_chunks = list(chunks(text, 50))\n","# print(token_chunks)\n","\n","responses = []\n","\n","for chunk in all_chunks:\n","    response = submit_to_api(chunk)\n","    if response is not None:\n","        print(\"hello\")\n","        responses.append(response)\n","\n","# Write responses to a JSON file\n","with open('response.json', 'w') as f:\n","    json.dump(responses, f)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}